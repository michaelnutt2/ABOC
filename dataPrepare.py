"""
Description: Prepare data for traning and testing.
             *.mat is generated by dataPrepare from *.ply
             *.mat data structure cell{N*4} :
                N: point clouds number; N=1 in '*.mat'
                    {
                        [TreePoints*K*C] Octree data sequence generated from PQ (Quantized point cloud): N*K*C [n,7,6] array
                                         N[n treepoints]  K[7 ancestors]   C[oct code,level,octant,position(xyz)]
                4:      {Location} Original geometric coordinate P (n*3)
                        {qs,offset,Lmax,name} side information; Quantized point cloud PQ = (P-offset)/qs; The depth of PQ; The name of P (point cloud)
                    }
"""
import glob
from Preparedata.data import dataPrepare
from networkTool import CPrintl


def makedFile(dir):
    fileList = sorted(glob.glob(dir))
    return fileList


if __name__ == "__main__":

    # ####For KITTI######
    oriDir = '/home/michael-nutt/Datasets/SemanticKITTI/dataset/sequences/'
    outDir = 'Data/Lidar/train/'
    ptNamePrefix = 'Kitti_'

    printl = CPrintl('Preparedata/makedFileLidar.log')

import os
import multiprocessing
from functools import partial

def process_file(args):
    file, outDir, ptNamePrefix, folder, qlevel = args
    fileName = folder + file.split('/')[-1][:-4]
    dataName = outDir + ptNamePrefix + fileName + '.fb'

    # dataPrepare generates .fb file internally now
    # We re-import here to ensure it works in worker process if needed,
    # though top-level import usually suffices on Linux (fork).
    # from Preparedata.data import dataPrepare

    try:
        dataPrepare(file, saveMatDir=outDir, ptNamePrefix=ptNamePrefix + folder, offset='min',
                    qs=2 / (2 ** qlevel - 1), normalize=True)
        return dataName
    except Exception as e:
        return f"Error processing {file}: {e}"

if __name__ == "__main__":

    # ####For KITTI######
    oriDir = '/home/michael-nutt/Datasets/SemanticKITTI/dataset/sequences/'
    outDir = 'Data/Lidar/train/'
    ptNamePrefix = 'Kitti_'

    printl = CPrintl('Preparedata/makedFileLidar.log')
    makeFileList = set(makedFile(outDir + '*.fb')) # Use set for O(1) lookup

    tasks = []

    # Configure for Test (Seq 00, 300 files) OR Full Run
    # Adjust range(0, 22) for full run
    for folder in range(0, 1):
        folder = '{:02d}'.format(folder)
        fileList = sorted(glob.glob(oriDir + folder + '/velodyne/*.bin'))

        for n, file in enumerate(fileList):
            if n >= 300: # Limit for test
                break

            fileName = folder + file.split('/')[-1][:-4]
            dataName = outDir + 'Kitti_' + fileName + '.fb'

            if dataName in makeFileList:
                print(dataName, 'maked!')
                continue

            qlevel = 12
            # Append task arguments
            tasks.append((file, outDir, ptNamePrefix, folder, qlevel))

    print(f"Starting parallel processing of {len(tasks)} files with {multiprocessing.cpu_count()} cores...")

    if tasks:
        with multiprocessing.Pool() as pool:
            # Use imap_unordered for better responsiveness during processing
            for i, result in enumerate(pool.imap_unordered(process_file, tasks)):
                if (i + 1) % 10 == 0:
                    printl(result) # Log progress

    print("Data preparation complete.")
